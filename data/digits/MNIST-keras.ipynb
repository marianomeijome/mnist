{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "X_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 12s 290us/step - loss: 2.2388 - acc: 0.7792 - val_loss: 0.4383 - val_acc: 0.8950\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 11s 258us/step - loss: 0.3200 - acc: 0.9148 - val_loss: 0.2757 - val_acc: 0.9271\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 11s 260us/step - loss: 0.2271 - acc: 0.9373 - val_loss: 0.2376 - val_acc: 0.9359\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 11s 260us/step - loss: 0.1920 - acc: 0.9469 - val_loss: 0.2144 - val_acc: 0.9404\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 11s 262us/step - loss: 0.1586 - acc: 0.9538 - val_loss: 0.2319 - val_acc: 0.9411\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 12s 284us/step - loss: 0.1410 - acc: 0.9599 - val_loss: 0.1803 - val_acc: 0.9508\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 13s 299us/step - loss: 0.1273 - acc: 0.9633 - val_loss: 0.1803 - val_acc: 0.9527\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 12s 276us/step - loss: 0.1125 - acc: 0.9677 - val_loss: 0.1838 - val_acc: 0.9528\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 11s 266us/step - loss: 0.1019 - acc: 0.9711 - val_loss: 0.1765 - val_acc: 0.9554\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 11s 271us/step - loss: 0.0938 - acc: 0.9728 - val_loss: 0.1582 - val_acc: 0.9607\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 11s 264us/step - loss: 0.0858 - acc: 0.9754 - val_loss: 0.1601 - val_acc: 0.9587\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 12s 282us/step - loss: 0.0823 - acc: 0.9771 - val_loss: 0.1726 - val_acc: 0.9593\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 11s 267us/step - loss: 0.0739 - acc: 0.9784 - val_loss: 0.1586 - val_acc: 0.9631\n",
      "Baseline Error: 3.13%\n"
     ]
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model_1.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model_1.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the third hidden layer\n",
    "model_1.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the fourth hidden layer\n",
    "model_1.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_1.fit(X_train, y_train, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model_1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 5s 113us/step - loss: 0.4990 - acc: 0.8421 - val_loss: 0.1176 - val_acc: 0.9653\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.1229 - acc: 0.9628 - val_loss: 0.0834 - val_acc: 0.9747\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0851 - acc: 0.9737 - val_loss: 0.0726 - val_acc: 0.9774\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0678 - acc: 0.9784 - val_loss: 0.0606 - val_acc: 0.9816\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 2s 50us/step - loss: 0.0606 - acc: 0.9813 - val_loss: 0.0628 - val_acc: 0.9819\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0526 - acc: 0.9832 - val_loss: 0.0491 - val_acc: 0.9850\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0466 - acc: 0.9852 - val_loss: 0.0535 - val_acc: 0.9844\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0415 - acc: 0.9868 - val_loss: 0.0468 - val_acc: 0.9852\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0377 - acc: 0.9881 - val_loss: 0.0456 - val_acc: 0.9860\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0337 - acc: 0.9892 - val_loss: 0.0440 - val_acc: 0.9868\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0342 - acc: 0.9889 - val_loss: 0.0421 - val_acc: 0.9871\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 2s 50us/step - loss: 0.0296 - acc: 0.9905 - val_loss: 0.0475 - val_acc: 0.9858\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 2s 50us/step - loss: 0.0294 - acc: 0.9902 - val_loss: 0.0425 - val_acc: 0.9864\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 2s 50us/step - loss: 0.0259 - acc: 0.9913 - val_loss: 0.0406 - val_acc: 0.9879\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0247 - acc: 0.9915 - val_loss: 0.0372 - val_acc: 0.9889\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0213 - acc: 0.9935 - val_loss: 0.0394 - val_acc: 0.9881\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 2s 48us/step - loss: 0.0200 - acc: 0.9936 - val_loss: 0.0363 - val_acc: 0.9889\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0207 - acc: 0.9934 - val_loss: 0.0405 - val_acc: 0.9885\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0210 - acc: 0.9925 - val_loss: 0.0380 - val_acc: 0.9883\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 2s 49us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0353 - val_acc: 0.9897\n",
      "Baseline Error: 0.76%\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_2.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_2.add(Dropout(0.2))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=20, batch_size=200, validation_split=0.3, callbacks = [early_stopping_monitor])\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model_2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This saves the architecture of the model, weights, training config (loss,optimizer), state of optimizer, allowing to resume training where we last left off</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('mnist_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "mnist_model = load_model('mnist_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 15)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               48128     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 59,933\n",
      "Trainable params: 59,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# productionizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist_model = load_model('mnist_cnn_model.h5')\n",
    "\n",
    "def predict_user_img(img_path, model):\n",
    "    # takes user image as input, preprocesses it,\n",
    "    # and returns the prediction\n",
    "    \n",
    "    img = cv2.imread(img_path, 0)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = cv2.bitwise_not(img)\n",
    "    \n",
    "    if(model == 'model_1'):\n",
    "        x = img.reshape(1,784).astype('float32')\n",
    "        probs = model_1.predict(x)\n",
    "        prediction = np.argmax(probs)\n",
    "        return prediction, plt.imshow(img)\n",
    "    \n",
    "    elif(model == 'mnist_model'):\n",
    "        x = img.reshape(1, 28, 28,1).astype('float32')\n",
    "        probs = mnist_model.predict(x)\n",
    "        prediction = np.argmax(probs)        \n",
    "        return prediction, plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, <matplotlib.image.AxesImage at 0x2a5173a5c50>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_user_img('digit3.png', 'mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "drawing=False # true if mouse is pressed\n",
    "mode=True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "\n",
    "# mouse callback function\n",
    "def interactive_drawing(event,x,y,flags,param):\n",
    "    global ix,iy,drawing, mode\n",
    "\n",
    "    if event==cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing=True\n",
    "        ix,iy=x,y\n",
    "\n",
    "    elif event==cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing==True:\n",
    "            if mode==True:\n",
    "                cv2.line(img,(ix,iy),(x,y),(0,0,255),10)\n",
    "                ix=x\n",
    "                iy=y\n",
    "\n",
    "#                 print (x,y)\n",
    "    elif event==cv2.EVENT_LBUTTONUP:\n",
    "        drawing=False\n",
    "        if mode==True:\n",
    "            cv2.line(img,(ix,iy),(x,y),(0,0,255),10)\n",
    "            ix=x\n",
    "            iy=y\n",
    "            #print x,y\n",
    "            #cv2.line(img,(x,y),(x,y),(0,0,255),10)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',interactive_drawing)\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k=cv2.waitKey(1)&0xFF\n",
    "    if k==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras)",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
